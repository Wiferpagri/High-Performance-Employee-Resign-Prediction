{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling full data\n",
    "\n",
    "Since our full data has many features due to node embeddings, we need to use robust models as XGBoost, Support Vector Machine and a Neural Network. The metric chosen metric for this evaluation is F1-Score because both classes have the same weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import optuna\n",
    "sys.path.append('../high_performance_employee_resign_prediction')\n",
    "from utils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(paths.data_processed_dir('train_processed.csv'))\n",
    "test_df = pd.read_csv(paths.data_processed_dir('test_processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving id_employee_employee for submission\n",
    "\n",
    "id_col = test_df['id_employee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['resign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "\n",
    "X = train_df.drop(columns=['id_employee', 'id_last_boss', 'resign'])\n",
    "X_test = test_df.drop(columns=['id_employee', 'id_last_boss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and optimizing neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X.to_numpy()).float()\n",
    "X_test_tensor = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_tensor = torch.from_numpy(y.to_numpy()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Neural Network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_layers, hidden_size, dropout_rate, activation_fn):\n",
    "        super(Net, self).__init__()\n",
    "        layers = []\n",
    "        in_size = input_size\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Linear(in_size, hidden_size))\n",
    "            layers.append(activation_fn)\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            in_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(in_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function to optimize with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining objective function\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256, log=True)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    activation_name = trial.suggest_categorical('activation', ['ReLU', 'LeakyReLU', 'ELU'])\n",
    "\n",
    "    # Choose activation function\n",
    "    if activation_name == 'ReLU':\n",
    "        activation_fn = nn.ReLU()\n",
    "    elif activation_name == 'LeakyReLU':\n",
    "        activation_fn = nn.LeakyReLU()\n",
    "    else:\n",
    "        activation_fn = nn.ELU()\n",
    "        \n",
    "    skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    f1_scores = []\n",
    "    \n",
    "\n",
    "    for train_index, val_index in skf.split(X_train_tensor, y_tensor):\n",
    "        X_train_fold = X_train_tensor[train_index]\n",
    "        y_train_fold = y_tensor[train_index]\n",
    "        X_val_fold = X_train_tensor[val_index]\n",
    "        y_val_fold = y_tensor[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "        val_dataset = TensorDataset(X_val_fold, y_val_fold)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        model = Net(input_size=X_train_tensor.shape[1],\n",
    "                    num_classes=2,\n",
    "                    num_layers=num_layers,\n",
    "                    hidden_size=hidden_size,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    activation_fn=activation_fn)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Early stopping parameters\n",
    "        best_val_f1 = 0\n",
    "        patience = 10\n",
    "        trigger_times = 0\n",
    "\n",
    "        for epoch in range(50):  # Max epochs\n",
    "            model.train()\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    outputs = model(X_batch)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    all_preds.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "            val_f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "\n",
    "            # Early stopping check\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                trigger_times = 0\n",
    "            else:\n",
    "                trigger_times += 1\n",
    "                if trigger_times >= patience:\n",
    "                    break  # Early stopping\n",
    "\n",
    "        f1_scores.append(best_val_f1)\n",
    "\n",
    "    # Return the average F1-score across folds\n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-27 22:03:08,497] A new study created in memory with name: no-name-e6dbe675-a897-4cfa-95f9-e9e83d114dd9\n",
      "[I 2024-10-27 22:03:26,129] Trial 0 finished with value: 0.740130659655074 and parameters: {'num_layers': 1, 'hidden_size': 38, 'dropout_rate': 0.12453051999907157, 'weight_decay': 1.3858937404360746e-05, 'learning_rate': 0.08941043367029315, 'batch_size': 64, 'activation': 'LeakyReLU'}. Best is trial 0 with value: 0.740130659655074.\n",
      "[I 2024-10-27 22:03:36,105] Trial 1 finished with value: 0.7347869153080807 and parameters: {'num_layers': 3, 'hidden_size': 88, 'dropout_rate': 0.24315879283583125, 'weight_decay': 2.8796386944145745e-05, 'learning_rate': 0.002818712122603081, 'batch_size': 64, 'activation': 'ReLU'}. Best is trial 0 with value: 0.740130659655074.\n",
      "[I 2024-10-27 22:03:44,057] Trial 2 finished with value: 0.7492799464777041 and parameters: {'num_layers': 1, 'hidden_size': 86, 'dropout_rate': 0.452977629854759, 'weight_decay': 0.007220364515880996, 'learning_rate': 0.0011277387357508909, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 2 with value: 0.7492799464777041.\n",
      "[I 2024-10-27 22:04:14,714] Trial 3 finished with value: 0.7540482348145943 and parameters: {'num_layers': 2, 'hidden_size': 185, 'dropout_rate': 0.14114668530450658, 'weight_decay': 4.195398878096833e-05, 'learning_rate': 0.0012347679575001604, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 3 with value: 0.7540482348145943.\n",
      "[I 2024-10-27 22:04:36,593] Trial 4 finished with value: 0.754910481787139 and parameters: {'num_layers': 1, 'hidden_size': 40, 'dropout_rate': 0.15491615254260252, 'weight_decay': 0.0034759237685640498, 'learning_rate': 0.0012445258586602393, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:04:42,366] Trial 5 finished with value: 0.7370328147095787 and parameters: {'num_layers': 2, 'hidden_size': 62, 'dropout_rate': 0.4447767469678592, 'weight_decay': 6.896565636724892e-05, 'learning_rate': 0.0037211350033358966, 'batch_size': 128, 'activation': 'ReLU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:04:48,212] Trial 6 finished with value: 0.7475165215015629 and parameters: {'num_layers': 1, 'hidden_size': 181, 'dropout_rate': 0.15539130866436335, 'weight_decay': 0.009912467380793518, 'learning_rate': 0.0224440828512143, 'batch_size': 128, 'activation': 'LeakyReLU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:05:10,694] Trial 7 finished with value: 0.7442707807283042 and parameters: {'num_layers': 3, 'hidden_size': 47, 'dropout_rate': 0.12770862575907194, 'weight_decay': 0.0009848397618294222, 'learning_rate': 0.0002854749536023257, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:05:39,476] Trial 8 finished with value: 0.7312564337639066 and parameters: {'num_layers': 3, 'hidden_size': 161, 'dropout_rate': 0.39501382844313426, 'weight_decay': 0.00020234603026387195, 'learning_rate': 0.00016267656141316625, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:05:46,013] Trial 9 finished with value: 0.7420735134538224 and parameters: {'num_layers': 1, 'hidden_size': 56, 'dropout_rate': 0.341852454005644, 'weight_decay': 0.00020695452957724653, 'learning_rate': 0.001814466218254777, 'batch_size': 64, 'activation': 'LeakyReLU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:06:07,834] Trial 10 finished with value: 0.7459437858504984 and parameters: {'num_layers': 2, 'hidden_size': 34, 'dropout_rate': 0.23743348766042088, 'weight_decay': 0.0016465704064649392, 'learning_rate': 0.011551849343189972, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:06:46,585] Trial 11 finished with value: 0.7538660494393884 and parameters: {'num_layers': 2, 'hidden_size': 240, 'dropout_rate': 0.2016614116585403, 'weight_decay': 0.0009691818389049545, 'learning_rate': 0.0005988508543804774, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:07:14,666] Trial 12 finished with value: 0.7517728664487413 and parameters: {'num_layers': 2, 'hidden_size': 129, 'dropout_rate': 0.288069453634374, 'weight_decay': 6.0266372947791954e-05, 'learning_rate': 0.0005384386125802289, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:07:31,167] Trial 13 finished with value: 0.7458747451924602 and parameters: {'num_layers': 1, 'hidden_size': 130, 'dropout_rate': 0.18771667507052908, 'weight_decay': 0.002388194217484695, 'learning_rate': 0.005910981071496655, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:07:52,074] Trial 14 finished with value: 0.7533684811069492 and parameters: {'num_layers': 2, 'hidden_size': 68, 'dropout_rate': 0.10332803585583086, 'weight_decay': 0.0003357228751655809, 'learning_rate': 0.001061558667079011, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:08:20,213] Trial 15 finished with value: 0.7376185709278541 and parameters: {'num_layers': 1, 'hidden_size': 113, 'dropout_rate': 0.3095346716239429, 'weight_decay': 1.2022386709821559e-05, 'learning_rate': 0.00012102960588050424, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:09:00,132] Trial 16 finished with value: 0.7449304399946086 and parameters: {'num_layers': 3, 'hidden_size': 207, 'dropout_rate': 0.1920683656467947, 'weight_decay': 0.0036087172476094546, 'learning_rate': 0.0003834878730658873, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:09:17,269] Trial 17 finished with value: 0.7465900859054069 and parameters: {'num_layers': 2, 'hidden_size': 41, 'dropout_rate': 0.2619987801091668, 'weight_decay': 0.0004883842078617501, 'learning_rate': 0.010132443987888155, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 4 with value: 0.754910481787139.\n",
      "[I 2024-10-27 22:09:31,495] Trial 18 finished with value: 0.7554890181089836 and parameters: {'num_layers': 1, 'hidden_size': 73, 'dropout_rate': 0.1629466698725622, 'weight_decay': 0.00010685301187725821, 'learning_rate': 0.0012863067595274523, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 18 with value: 0.7554890181089836.\n",
      "[I 2024-10-27 22:09:41,693] Trial 19 finished with value: 0.7152546397932303 and parameters: {'num_layers': 1, 'hidden_size': 76, 'dropout_rate': 0.3570852311742404, 'weight_decay': 0.00019167481453377365, 'learning_rate': 0.05060038165453772, 'batch_size': 32, 'activation': 'LeakyReLU'}. Best is trial 18 with value: 0.7554890181089836.\n",
      "[I 2024-10-27 22:09:49,802] Trial 20 finished with value: 0.7457454533024365 and parameters: {'num_layers': 1, 'hidden_size': 53, 'dropout_rate': 0.1709331163920301, 'weight_decay': 9.21900528777307e-05, 'learning_rate': 0.003105619804174105, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 18 with value: 0.7554890181089836.\n",
      "[I 2024-10-27 22:10:01,446] Trial 21 finished with value: 0.7557986662966953 and parameters: {'num_layers': 1, 'hidden_size': 120, 'dropout_rate': 0.1494394411417773, 'weight_decay': 4.04332446196709e-05, 'learning_rate': 0.0011759416794200235, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 21 with value: 0.7557986662966953.\n",
      "[I 2024-10-27 22:10:14,975] Trial 22 finished with value: 0.7541478815561683 and parameters: {'num_layers': 1, 'hidden_size': 113, 'dropout_rate': 0.2153868754903035, 'weight_decay': 0.00010980041428924745, 'learning_rate': 0.0007435210121534701, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 21 with value: 0.7557986662966953.\n",
      "[I 2024-10-27 22:10:32,318] Trial 23 finished with value: 0.742466443850148 and parameters: {'num_layers': 1, 'hidden_size': 101, 'dropout_rate': 0.10914632159345147, 'weight_decay': 2.5519802059408727e-05, 'learning_rate': 0.00025424305022997006, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 21 with value: 0.7557986662966953.\n",
      "[I 2024-10-27 22:10:44,080] Trial 24 finished with value: 0.7548228803806997 and parameters: {'num_layers': 1, 'hidden_size': 146, 'dropout_rate': 0.16090460541979662, 'weight_decay': 0.0004430973863304713, 'learning_rate': 0.0018115116610265829, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 21 with value: 0.7557986662966953.\n",
      "[I 2024-10-27 22:10:54,632] Trial 25 finished with value: 0.756051292960486 and parameters: {'num_layers': 1, 'hidden_size': 32, 'dropout_rate': 0.22598437397450155, 'weight_decay': 0.00013141416612146795, 'learning_rate': 0.002503605404883859, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 25 with value: 0.756051292960486.\n",
      "[I 2024-10-27 22:11:04,623] Trial 26 finished with value: 0.7557477598377124 and parameters: {'num_layers': 1, 'hidden_size': 33, 'dropout_rate': 0.22092094208122975, 'weight_decay': 0.00014229360086351803, 'learning_rate': 0.005154137278996526, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 25 with value: 0.756051292960486.\n",
      "[I 2024-10-27 22:11:14,771] Trial 27 finished with value: 0.7519325126961053 and parameters: {'num_layers': 1, 'hidden_size': 46, 'dropout_rate': 0.27153229927036887, 'weight_decay': 2.20526880163995e-05, 'learning_rate': 0.007872606691382893, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 25 with value: 0.756051292960486.\n",
      "[I 2024-10-27 22:11:22,718] Trial 28 finished with value: 0.7291128084889273 and parameters: {'num_layers': 1, 'hidden_size': 34, 'dropout_rate': 0.49988931613570037, 'weight_decay': 4.416710465488751e-05, 'learning_rate': 0.017896591982820606, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 25 with value: 0.756051292960486.\n",
      "[I 2024-10-27 22:11:26,383] Trial 29 finished with value: 0.7390223540620011 and parameters: {'num_layers': 1, 'hidden_size': 32, 'dropout_rate': 0.2386482131877492, 'weight_decay': 0.00014415024119285912, 'learning_rate': 0.005041992841175278, 'batch_size': 128, 'activation': 'LeakyReLU'}. Best is trial 25 with value: 0.756051292960486.\n",
      "[I 2024-10-27 22:11:38,510] Trial 30 finished with value: 0.7152068559614106 and parameters: {'num_layers': 2, 'hidden_size': 44, 'dropout_rate': 0.2177488909704869, 'weight_decay': 1.7169677523383088e-05, 'learning_rate': 0.09923497535281917, 'batch_size': 32, 'activation': 'LeakyReLU'}. Best is trial 25 with value: 0.756051292960486.\n",
      "[I 2024-10-27 22:11:50,655] Trial 31 finished with value: 0.757066320218645 and parameters: {'num_layers': 1, 'hidden_size': 52, 'dropout_rate': 0.18287125100073182, 'weight_decay': 9.486865417330434e-05, 'learning_rate': 0.0020579505611290285, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:12:01,397] Trial 32 finished with value: 0.7561441547126014 and parameters: {'num_layers': 1, 'hidden_size': 37, 'dropout_rate': 0.22313640507660903, 'weight_decay': 4.735613396567591e-05, 'learning_rate': 0.0023895964674876453, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:12:13,787] Trial 33 finished with value: 0.7531567736042687 and parameters: {'num_layers': 1, 'hidden_size': 37, 'dropout_rate': 0.18891565606009217, 'weight_decay': 3.942973320010622e-05, 'learning_rate': 0.0020732262932237665, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:12:24,251] Trial 34 finished with value: 0.7522927299802469 and parameters: {'num_layers': 1, 'hidden_size': 51, 'dropout_rate': 0.25692103510308895, 'weight_decay': 6.527384465385192e-05, 'learning_rate': 0.002605342291687789, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:12:34,501] Trial 35 finished with value: 0.7472854363437345 and parameters: {'num_layers': 1, 'hidden_size': 38, 'dropout_rate': 0.12690415279963016, 'weight_decay': 4.2114777177856023e-05, 'learning_rate': 0.0008086273107042559, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:12:46,084] Trial 36 finished with value: 0.7542517303579495 and parameters: {'num_layers': 1, 'hidden_size': 82, 'dropout_rate': 0.28592279083729655, 'weight_decay': 2.84381443032327e-05, 'learning_rate': 0.0036787355940628257, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:12:53,055] Trial 37 finished with value: 0.7411955435596608 and parameters: {'num_layers': 2, 'hidden_size': 63, 'dropout_rate': 0.13395783753132007, 'weight_decay': 1.0121706534716333e-05, 'learning_rate': 0.0022033856901593624, 'batch_size': 64, 'activation': 'ReLU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:13:00,111] Trial 38 finished with value: 0.7474687611161814 and parameters: {'num_layers': 1, 'hidden_size': 100, 'dropout_rate': 0.32202372557046083, 'weight_decay': 7.354786040119812e-05, 'learning_rate': 0.0015158869248285919, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:13:11,172] Trial 39 finished with value: 0.7502720300060483 and parameters: {'num_layers': 1, 'hidden_size': 40, 'dropout_rate': 0.17451265926825296, 'weight_decay': 1.5587758512620618e-05, 'learning_rate': 0.0010200326640248086, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:13:21,696] Trial 40 finished with value: 0.737412085199888 and parameters: {'num_layers': 2, 'hidden_size': 57, 'dropout_rate': 0.23785451376227826, 'weight_decay': 5.24113647109818e-05, 'learning_rate': 0.0038437477780370313, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:13:30,455] Trial 41 finished with value: 0.7497982308832618 and parameters: {'num_layers': 1, 'hidden_size': 35, 'dropout_rate': 0.21423429060507085, 'weight_decay': 0.0001528619864506094, 'learning_rate': 0.0049475435931736166, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:13:38,171] Trial 42 finished with value: 0.7530996271516031 and parameters: {'num_layers': 1, 'hidden_size': 32, 'dropout_rate': 0.14909693037303107, 'weight_decay': 0.00032170743110073894, 'learning_rate': 0.006920226951196911, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 31 with value: 0.757066320218645.\n",
      "[I 2024-10-27 22:13:49,619] Trial 43 finished with value: 0.7570672118495753 and parameters: {'num_layers': 1, 'hidden_size': 42, 'dropout_rate': 0.21357806339290178, 'weight_decay': 0.00014215700676985203, 'learning_rate': 0.0028224939080356854, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:14:01,355] Trial 44 finished with value: 0.7541864139162133 and parameters: {'num_layers': 1, 'hidden_size': 48, 'dropout_rate': 0.20098672628654735, 'weight_decay': 0.000219344320823174, 'learning_rate': 0.0014251900285148944, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:14:07,615] Trial 45 finished with value: 0.7511575312083989 and parameters: {'num_layers': 1, 'hidden_size': 43, 'dropout_rate': 0.14619285729852702, 'weight_decay': 9.148175921821522e-05, 'learning_rate': 0.002719319614991118, 'batch_size': 128, 'activation': 'LeakyReLU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:14:16,788] Trial 46 finished with value: 0.7341752612424339 and parameters: {'num_layers': 1, 'hidden_size': 40, 'dropout_rate': 0.17539782624452363, 'weight_decay': 0.0002521231670106499, 'learning_rate': 0.0004858149142311862, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:14:30,625] Trial 47 finished with value: 0.748967759276652 and parameters: {'num_layers': 1, 'hidden_size': 50, 'dropout_rate': 0.22820237236901503, 'weight_decay': 3.391642141874045e-05, 'learning_rate': 0.0009147370297714965, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:14:44,823] Trial 48 finished with value: 0.7384659307059162 and parameters: {'num_layers': 3, 'hidden_size': 59, 'dropout_rate': 0.2026616104143151, 'weight_decay': 6.76922760464344e-05, 'learning_rate': 0.0016010775516876825, 'batch_size': 32, 'activation': 'ReLU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:14:55,783] Trial 49 finished with value: 0.7538054822500253 and parameters: {'num_layers': 1, 'hidden_size': 37, 'dropout_rate': 0.11702135071814163, 'weight_decay': 0.000608084504613327, 'learning_rate': 0.0027840986796422713, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:15:12,934] Trial 50 finished with value: 0.7513608948115569 and parameters: {'num_layers': 2, 'hidden_size': 92, 'dropout_rate': 0.25507110079850126, 'weight_decay': 0.00014547778941874842, 'learning_rate': 0.003893771256285262, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:15:20,950] Trial 51 finished with value: 0.7518324481651856 and parameters: {'num_layers': 1, 'hidden_size': 34, 'dropout_rate': 0.22589851331111405, 'weight_decay': 0.00012377501998497536, 'learning_rate': 0.009607022312751321, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:15:27,981] Trial 52 finished with value: 0.750356263251652 and parameters: {'num_layers': 1, 'hidden_size': 43, 'dropout_rate': 0.18242634838812466, 'weight_decay': 5.448058035209121e-05, 'learning_rate': 0.00480304362804043, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:15:38,861] Trial 53 finished with value: 0.7509075457847361 and parameters: {'num_layers': 1, 'hidden_size': 32, 'dropout_rate': 0.2752517826624613, 'weight_decay': 8.3881440476549e-05, 'learning_rate': 0.01638156433577764, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:15:48,206] Trial 54 finished with value: 0.7535455610524198 and parameters: {'num_layers': 1, 'hidden_size': 37, 'dropout_rate': 0.20147857622517618, 'weight_decay': 0.00015975170271031322, 'learning_rate': 0.002488123691903423, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:15:58,361] Trial 55 finished with value: 0.7320699404280111 and parameters: {'num_layers': 1, 'hidden_size': 158, 'dropout_rate': 0.24968033903204598, 'weight_decay': 0.00026491672372849914, 'learning_rate': 0.03770232959609793, 'batch_size': 32, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:16:04,103] Trial 56 finished with value: 0.7543373377212335 and parameters: {'num_layers': 1, 'hidden_size': 46, 'dropout_rate': 0.3034742488120571, 'weight_decay': 0.00010769353980102281, 'learning_rate': 0.00696990368567608, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:16:14,854] Trial 57 finished with value: 0.7559935442398525 and parameters: {'num_layers': 1, 'hidden_size': 130, 'dropout_rate': 0.16434101364575096, 'weight_decay': 2.1449455587633656e-05, 'learning_rate': 0.0019463075383266387, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:16:21,419] Trial 58 finished with value: 0.7386567367465983 and parameters: {'num_layers': 1, 'hidden_size': 129, 'dropout_rate': 0.14174794362182555, 'weight_decay': 1.899254756720966e-05, 'learning_rate': 0.0007058462787133119, 'batch_size': 64, 'activation': 'LeakyReLU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:16:30,568] Trial 59 finished with value: 0.753232381787757 and parameters: {'num_layers': 1, 'hidden_size': 145, 'dropout_rate': 0.16240390445424385, 'weight_decay': 3.512439014677751e-05, 'learning_rate': 0.0011948165599821841, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:16:44,640] Trial 60 finished with value: 0.753614982804254 and parameters: {'num_layers': 3, 'hidden_size': 116, 'dropout_rate': 0.18806116407802012, 'weight_decay': 2.117363653624298e-05, 'learning_rate': 0.0020280925775817064, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 43 with value: 0.7570672118495753.\n",
      "[I 2024-10-27 22:16:54,017] Trial 61 finished with value: 0.7571839539727525 and parameters: {'num_layers': 1, 'hidden_size': 184, 'dropout_rate': 0.21012138500516625, 'weight_decay': 5.080777941943232e-05, 'learning_rate': 0.0032836455443706974, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 61 with value: 0.7571839539727525.\n",
      "[I 2024-10-27 22:17:03,811] Trial 62 finished with value: 0.7580465115227037 and parameters: {'num_layers': 1, 'hidden_size': 190, 'dropout_rate': 0.20863412311230853, 'weight_decay': 5.164862478576171e-05, 'learning_rate': 0.0032997430035864523, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:17:11,514] Trial 63 finished with value: 0.7562008214191758 and parameters: {'num_layers': 1, 'hidden_size': 191, 'dropout_rate': 0.20834928755646817, 'weight_decay': 5.4974750405189904e-05, 'learning_rate': 0.003083896959846539, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:17:21,108] Trial 64 finished with value: 0.7533762877760174 and parameters: {'num_layers': 1, 'hidden_size': 223, 'dropout_rate': 0.23323215531672076, 'weight_decay': 5.113737341585621e-05, 'learning_rate': 0.003642212443261487, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:17:31,307] Trial 65 finished with value: 0.7575695206051769 and parameters: {'num_layers': 1, 'hidden_size': 195, 'dropout_rate': 0.20888311368987572, 'weight_decay': 6.966941296348985e-05, 'learning_rate': 0.0034181598205037986, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:17:40,555] Trial 66 finished with value: 0.753871229725851 and parameters: {'num_layers': 1, 'hidden_size': 189, 'dropout_rate': 0.20646506537710352, 'weight_decay': 7.625123864395324e-05, 'learning_rate': 0.0032573530569285367, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:17:49,417] Trial 67 finished with value: 0.7541593945243154 and parameters: {'num_layers': 1, 'hidden_size': 253, 'dropout_rate': 0.38018329735745116, 'weight_decay': 6.11818804678603e-05, 'learning_rate': 0.004175879343762664, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:17:56,424] Trial 68 finished with value: 0.7431218995497458 and parameters: {'num_layers': 1, 'hidden_size': 202, 'dropout_rate': 0.24611515790829036, 'weight_decay': 3.2222936476991627e-05, 'learning_rate': 0.005886340597871657, 'batch_size': 64, 'activation': 'ReLU'}. Best is trial 62 with value: 0.7580465115227037.\n",
      "[I 2024-10-27 22:18:08,647] Trial 69 finished with value: 0.7600680004864413 and parameters: {'num_layers': 1, 'hidden_size': 169, 'dropout_rate': 0.2691771974330077, 'weight_decay': 9.887535613980591e-05, 'learning_rate': 0.0031214454579186267, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:18:17,746] Trial 70 finished with value: 0.7343282080850171 and parameters: {'num_layers': 2, 'hidden_size': 177, 'dropout_rate': 0.27556814135493024, 'weight_decay': 0.00010207035436471565, 'learning_rate': 0.012646980391074137, 'batch_size': 64, 'activation': 'LeakyReLU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:18:26,695] Trial 71 finished with value: 0.7515131482055617 and parameters: {'num_layers': 1, 'hidden_size': 171, 'dropout_rate': 0.2128292745407546, 'weight_decay': 4.7514690314964574e-05, 'learning_rate': 0.0033031895809654604, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:18:37,883] Trial 72 finished with value: 0.7549811021739397 and parameters: {'num_layers': 1, 'hidden_size': 214, 'dropout_rate': 0.19375488034604824, 'weight_decay': 8.360061149404721e-05, 'learning_rate': 0.0016529859393891585, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:18:49,503] Trial 73 finished with value: 0.7564874794401305 and parameters: {'num_layers': 1, 'hidden_size': 191, 'dropout_rate': 0.2685153136738375, 'weight_decay': 2.9435584125711886e-05, 'learning_rate': 0.002288947460743653, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:18:58,399] Trial 74 finished with value: 0.7569240434678128 and parameters: {'num_layers': 1, 'hidden_size': 192, 'dropout_rate': 0.31840851238397333, 'weight_decay': 2.734556166221945e-05, 'learning_rate': 0.003004359468601117, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:19:08,871] Trial 75 finished with value: 0.757671227105923 and parameters: {'num_layers': 1, 'hidden_size': 157, 'dropout_rate': 0.3284367133102249, 'weight_decay': 2.4204919681924916e-05, 'learning_rate': 0.006068451619881196, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:19:15,184] Trial 76 finished with value: 0.7545935251357496 and parameters: {'num_layers': 1, 'hidden_size': 165, 'dropout_rate': 0.32866334035195055, 'weight_decay': 1.4395996837306078e-05, 'learning_rate': 0.008197547969382388, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:19:22,627] Trial 77 finished with value: 0.7520420956517732 and parameters: {'num_layers': 1, 'hidden_size': 153, 'dropout_rate': 0.35886270046624763, 'weight_decay': 2.6730986450930753e-05, 'learning_rate': 0.006239145652958911, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:19:31,736] Trial 78 finished with value: 0.7568572275005836 and parameters: {'num_layers': 1, 'hidden_size': 238, 'dropout_rate': 0.2898221138582368, 'weight_decay': 1.200552848047378e-05, 'learning_rate': 0.004160620927368371, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:19:39,996] Trial 79 finished with value: 0.7523238802862842 and parameters: {'num_layers': 1, 'hidden_size': 142, 'dropout_rate': 0.3469766587600048, 'weight_decay': 3.716268002430713e-05, 'learning_rate': 0.004498619203542925, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:19:54,766] Trial 80 finished with value: 0.7456527041010945 and parameters: {'num_layers': 1, 'hidden_size': 223, 'dropout_rate': 0.31179860833925066, 'weight_decay': 0.00011866863822491631, 'learning_rate': 0.005658855401203368, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:20:06,037] Trial 81 finished with value: 0.75606125243339 and parameters: {'num_layers': 1, 'hidden_size': 236, 'dropout_rate': 0.2899869946395935, 'weight_decay': 1.2181753384449932e-05, 'learning_rate': 0.002953946824872508, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:20:14,437] Trial 82 finished with value: 0.7567100684714905 and parameters: {'num_layers': 1, 'hidden_size': 179, 'dropout_rate': 0.31961561964633406, 'weight_decay': 2.3619354920584827e-05, 'learning_rate': 0.0044075715807720345, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:20:24,570] Trial 83 finished with value: 0.7541474272628468 and parameters: {'num_layers': 1, 'hidden_size': 203, 'dropout_rate': 0.3360722719751753, 'weight_decay': 1.790258534644945e-05, 'learning_rate': 0.001920661667611757, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:20:33,227] Trial 84 finished with value: 0.7498897663828665 and parameters: {'num_layers': 1, 'hidden_size': 231, 'dropout_rate': 0.2929147830557398, 'weight_decay': 0.00018137258035647285, 'learning_rate': 0.007743595226964362, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:20:44,378] Trial 85 finished with value: 0.7501091248379348 and parameters: {'num_layers': 1, 'hidden_size': 251, 'dropout_rate': 0.4394123419885609, 'weight_decay': 0.007282443863361984, 'learning_rate': 0.0035495675607649315, 'batch_size': 64, 'activation': 'ReLU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:20:54,569] Trial 86 finished with value: 0.7572156842717244 and parameters: {'num_layers': 1, 'hidden_size': 198, 'dropout_rate': 0.3670495437042747, 'weight_decay': 1.2570547417833175e-05, 'learning_rate': 0.005441274110712204, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:21:04,828] Trial 87 finished with value: 0.7516329493178164 and parameters: {'num_layers': 1, 'hidden_size': 169, 'dropout_rate': 0.3916360417368294, 'weight_decay': 4.251141594004406e-05, 'learning_rate': 0.0013627799186005395, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:21:13,222] Trial 88 finished with value: 0.7490654419397559 and parameters: {'num_layers': 1, 'hidden_size': 196, 'dropout_rate': 0.3709096981200436, 'weight_decay': 6.160334717801207e-05, 'learning_rate': 0.012056582218390382, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:21:20,741] Trial 89 finished with value: 0.7466079524905933 and parameters: {'num_layers': 1, 'hidden_size': 210, 'dropout_rate': 0.40655391843590977, 'weight_decay': 9.786973415539618e-05, 'learning_rate': 0.008989980012382959, 'batch_size': 64, 'activation': 'LeakyReLU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:21:35,236] Trial 90 finished with value: 0.743857145797771 and parameters: {'num_layers': 1, 'hidden_size': 181, 'dropout_rate': 0.34071469687573624, 'weight_decay': 2.545173141902832e-05, 'learning_rate': 0.005422394917376121, 'batch_size': 16, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:21:45,909] Trial 91 finished with value: 0.7518868641667795 and parameters: {'num_layers': 1, 'hidden_size': 216, 'dropout_rate': 0.3036004907207927, 'weight_decay': 1.6811986359933836e-05, 'learning_rate': 0.0026830696682928873, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:21:54,601] Trial 92 finished with value: 0.7518795541810909 and parameters: {'num_layers': 1, 'hidden_size': 200, 'dropout_rate': 0.3564353996671432, 'weight_decay': 1.2521453875709168e-05, 'learning_rate': 0.004369816033498942, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:02,927] Trial 93 finished with value: 0.7526313429839708 and parameters: {'num_layers': 1, 'hidden_size': 155, 'dropout_rate': 0.2831122204136011, 'weight_decay': 7.143769925286704e-05, 'learning_rate': 0.0063087638148243, 'batch_size': 64, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:11,038] Trial 94 finished with value: 0.7573972194388467 and parameters: {'num_layers': 1, 'hidden_size': 171, 'dropout_rate': 0.3160248758610813, 'weight_decay': 1.142133839790771e-05, 'learning_rate': 0.0023637525887974203, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:18,664] Trial 95 finished with value: 0.7580322573983709 and parameters: {'num_layers': 1, 'hidden_size': 138, 'dropout_rate': 0.31497924350288753, 'weight_decay': 2.0040277529547847e-05, 'learning_rate': 0.0023452885456345233, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:27,103] Trial 96 finished with value: 0.7583714381603052 and parameters: {'num_layers': 1, 'hidden_size': 173, 'dropout_rate': 0.19508462172906116, 'weight_decay': 1.980590560155596e-05, 'learning_rate': 0.0017527187699768712, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:34,965] Trial 97 finished with value: 0.7564890562951189 and parameters: {'num_layers': 1, 'hidden_size': 138, 'dropout_rate': 0.19575667096391985, 'weight_decay': 1.031680866097526e-05, 'learning_rate': 0.0024732805411977056, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:44,302] Trial 98 finished with value: 0.753588238549896 and parameters: {'num_layers': 1, 'hidden_size': 163, 'dropout_rate': 0.32974210869239395, 'weight_decay': 2.0030380260469085e-05, 'learning_rate': 0.0016798788834472725, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n",
      "[I 2024-10-27 22:22:53,113] Trial 99 finished with value: 0.7507906356630732 and parameters: {'num_layers': 1, 'hidden_size': 172, 'dropout_rate': 0.42298201491839865, 'weight_decay': 1.4756738040491402e-05, 'learning_rate': 0.0022375965538929646, 'batch_size': 128, 'activation': 'ELU'}. Best is trial 69 with value: 0.7600680004864413.\n"
     ]
    }
   ],
   "source": [
    "# Optimizing hyperparameters:\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "  num_layers: 1\n",
      "  hidden_size: 169\n",
      "  dropout_rate: 0.2691771974330077\n",
      "  weight_decay: 9.887535613980591e-05\n",
      "  learning_rate: 0.0031214454579186267\n",
      "  batch_size: 64\n",
      "  activation: ELU\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "\n",
    "# Use the entire training set\n",
    "train_dataset = TensorDataset(X_train_tensor, y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "\n",
    "# Initialize the model with best hyperparameters\n",
    "if best_params['activation'] == 'ReLU':\n",
    "    activation_fn = nn.ReLU()\n",
    "elif best_params['activation'] == 'LeakyReLU':\n",
    "    activation_fn = nn.LeakyReLU()\n",
    "else:\n",
    "    activation_fn = nn.ELU()\n",
    "\n",
    "model = Net(input_size=X_train_tensor.shape[1],\n",
    "            num_classes=2,\n",
    "            num_layers=best_params['num_layers'],\n",
    "            hidden_size=best_params['hidden_size'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            activation_fn=activation_fn\n",
    "            )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(50):  # Adjust epochs as needed\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test data\n",
    "test_loader = DataLoader(X_test_tensor, batch_size=best_params['batch_size'])\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "nn_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        # Getting outputs\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # Get the predicted class (0 or 1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Append the predicted class to test_predictions\n",
    "        nn_pred.extend(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving predicted values\n",
    "\n",
    "sub_nn = pd.DataFrame(nn_pred, columns=['abandono_6meses'])\n",
    "sub_nn = pd.concat([id_col, sub_nn], axis=1)\n",
    "sub_nn.rename(columns={'id_employee': 'ID'}, inplace=True)\n",
    "sub_nn.to_csv('../results/sub_nn_rfe_manual.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score: 0.5989"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
