{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "Categorical columns will be encoded using One-Hot encoding.\n",
    "\n",
    "Since distributions are not normal, we gonna use Power Transformer from Scikit-Learn to make them normal-like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer, LabelEncoder\n",
    "from autofeat import AutoFeatClassifier\n",
    "import sys\n",
    "sys.path.append('../high_performance_employee_resign_prediction')\n",
    "from utils import paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(paths.data_interim_dir('train_node.csv'))\n",
    "test_df = pd.read_csv(paths.data_interim_dir('test_node.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = ['id_employee_employee']\n",
    "\n",
    "num_cols = ['office_distance_employee', 'low_health_days_employee', 'average_permanence_employee', 'salary_employee',\n",
    "            'performance_score_employee', 'psi_score_employee', 'join_age_employee', 'office_distance_boss',\n",
    "            'low_health_days_boss', 'average_permanence_boss', 'salary_boss', 'performance_score_boss',\n",
    "            'psi_score_boss', 'join_age_boss', 'office_distance_diff', 'low_health_days_diff', 'average_permanence_diff',\n",
    "            'salary_diff', 'join_days_diff', 'age_diff', 'avg_od_epb', 'avg_lhd_epb', 'avg_avgp_epb', 'avg_sal_epb',\n",
    "            'avg_ps_epb', 'avg_psis_epb', 'avg_ja_epb', 'avg_od_bpb', 'avg_lhd_bpb', 'avg_avgp_bpb', 'avg_sal_bpb',\n",
    "            'avg_ps_bpb', 'avg_psis_bpb', 'avg_ja_bpb', 'boss_employees_in_charge', 'bob_bosses_in_charge']\n",
    "\n",
    "cat_cols = ['seniority_employee', 'work_modality_employee', 'gender_employee',\n",
    "            'recruitment_channel_employee', 'marital_estatus_employee', 'performance_employee',\n",
    "            'work_modality_boss', 'gender_boss', 'recruitment_channel_boss', 'marital_estatus_boss',\n",
    "            'performance_boss', 'joined_after_boss', 'younger_than_boss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding id_last_boss_employee and id_last_boss_boss columns\n",
    "\n",
    "boss_ids = pd.concat([train_df['id_last_boss_employee'], test_df['id_last_boss_employee']], axis=0).unique().tolist()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(boss_ids)\n",
    "\n",
    "train_df['id_last_boss_employee'] = label_encoder.transform(train_df['id_last_boss_employee'])\n",
    "train_df['id_last_boss_boss'] = label_encoder.transform(train_df['id_last_boss_boss'])\n",
    "test_df['id_last_boss_employee'] = label_encoder.transform(test_df['id_last_boss_employee'])\n",
    "test_df['id_last_boss_boss'] = label_encoder.transform(test_df['id_last_boss_boss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving id_employee\n",
    "\n",
    "train_id = train_df['id_employee_employee']\n",
    "test_id = train_df['id_employee_employee']\n",
    "\n",
    "train_df.drop(columns=['id_employee_employee'], inplace=True)\n",
    "test_df.drop(columns=['id_employee_employee'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[cat_cols] = train_df[cat_cols].astype('category')\n",
    "test_df[cat_cols] = test_df[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc_full = LabelEncoder()\n",
    "\n",
    "for col in cat_cols:\n",
    "    train_df[col] = label_enc_full.fit_transform(train_df[col])\n",
    "    test_df[col] = label_enc_full.transform(test_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "train_df.loc[:, num_cols] = scaler.fit_transform(train_df[num_cols])\n",
    "test_df.loc[:, num_cols] = scaler.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat_train = train_df.iloc[:, -193:]\n",
    "\n",
    "node_feat_test = test_df.iloc[:, -192:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_train_df = train_df.iloc[:, :-193]\n",
    "\n",
    "og_test_df = test_df.iloc[:, :-192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2152 entries, 0 to 2151\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   id_last_boss_employee         2152 non-null   int64  \n",
      " 1   seniority_employee            2152 non-null   int64  \n",
      " 2   work_modality_employee        2152 non-null   int32  \n",
      " 3   office_distance_employee      2152 non-null   float64\n",
      " 4   low_health_days_employee      2152 non-null   float64\n",
      " 5   gender_employee               2152 non-null   int32  \n",
      " 6   recruitment_channel_employee  2152 non-null   int32  \n",
      " 7   average_permanence_employee   2152 non-null   float64\n",
      " 8   salary_employee               2152 non-null   float64\n",
      " 9   performance_score_employee    2152 non-null   float64\n",
      " 10  psi_score_employee            2152 non-null   float64\n",
      " 11  marital_estatus_employee      2152 non-null   int32  \n",
      " 12  join_age_employee             2152 non-null   float64\n",
      " 13  join_year_employee            2152 non-null   int64  \n",
      " 14  join_month_employee           2152 non-null   int64  \n",
      " 15  performance_employee          2152 non-null   int32  \n",
      " 16  id_last_boss_boss             2152 non-null   int64  \n",
      " 17  work_modality_boss            2152 non-null   int32  \n",
      " 18  office_distance_boss          2152 non-null   float64\n",
      " 19  low_health_days_boss          2152 non-null   float64\n",
      " 20  gender_boss                   2152 non-null   int32  \n",
      " 21  recruitment_channel_boss      2152 non-null   int32  \n",
      " 22  average_permanence_boss       2152 non-null   float64\n",
      " 23  salary_boss                   2152 non-null   float64\n",
      " 24  performance_score_boss        2152 non-null   float64\n",
      " 25  psi_score_boss                2152 non-null   float64\n",
      " 26  marital_estatus_boss          2152 non-null   int32  \n",
      " 27  join_age_boss                 2152 non-null   float64\n",
      " 28  join_year_boss                2152 non-null   int64  \n",
      " 29  join_month_boss               2152 non-null   int64  \n",
      " 30  performance_boss              2152 non-null   int32  \n",
      " 31  office_distance_diff          2152 non-null   float64\n",
      " 32  low_health_days_diff          2152 non-null   float64\n",
      " 33  average_permanence_diff       2152 non-null   float64\n",
      " 34  salary_diff                   2152 non-null   float64\n",
      " 35  join_days_diff                2152 non-null   float64\n",
      " 36  joined_after_boss             2152 non-null   int64  \n",
      " 37  age_diff                      2152 non-null   float64\n",
      " 38  younger_than_boss             2152 non-null   int64  \n",
      " 39  avg_od_epb                    2152 non-null   float64\n",
      " 40  avg_lhd_epb                   2152 non-null   float64\n",
      " 41  avg_avgp_epb                  2152 non-null   float64\n",
      " 42  avg_sal_epb                   2152 non-null   float64\n",
      " 43  avg_ps_epb                    2152 non-null   float64\n",
      " 44  avg_psis_epb                  2152 non-null   float64\n",
      " 45  avg_ja_epb                    2152 non-null   float64\n",
      " 46  avg_od_bpb                    2152 non-null   float64\n",
      " 47  avg_lhd_bpb                   2152 non-null   float64\n",
      " 48  avg_avgp_bpb                  2152 non-null   float64\n",
      " 49  avg_sal_bpb                   2152 non-null   float64\n",
      " 50  avg_ps_bpb                    2152 non-null   float64\n",
      " 51  avg_psis_bpb                  2152 non-null   float64\n",
      " 52  avg_ja_bpb                    2152 non-null   float64\n",
      " 53  boss_employees_in_charge      2152 non-null   float64\n",
      " 54  bob_bosses_in_charge          2152 non-null   float64\n",
      "dtypes: float64(36), int32(10), int64(9)\n",
      "memory usage: 840.8 KB\n"
     ]
    }
   ],
   "source": [
    "og_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping features according to hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_feat = ['join_month_employee', 'work_modality_boss', 'gender_boss', 'recruitment_channel_boss',\n",
    "                'marital_estatus_boss', 'join_month_boss', 'performance_boss', 'joined_after_boss',\n",
    "                'younger_than_boss', 'office_distance_employee', 'average_permanence_employee', 'salary_employee',\n",
    "                'psi_score_employee', 'join_age_employee', 'office_distance_boss', 'low_health_days_boss',\n",
    "                'average_permanence_boss', 'salary_boss', 'psi_score_boss', 'join_age_boss',\n",
    "                'office_distance_diff', 'average_permanence_diff', 'age_diff', 'avg_od_epb',\n",
    "                'avg_lhd_epb', 'avg_avgp_epb', 'avg_sal_epb', 'avg_psis_epb', 'avg_od_bpb',\n",
    "                'avg_lhd_bpb', 'avg_avgp_bpb', 'avg_sal_bpb', 'avg_psis_bpb', 'avg_ja_bpb',\n",
    "                'boss_employees_in_charge', 'bob_bosses_in_charge']\n",
    "\n",
    "og_reduced_train_df = og_train_df.drop(columns=discard_feat)\n",
    "\n",
    "og_reduced_test_df = og_test_df.drop(columns=discard_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering on full data\n",
    "\n",
    "Autofeat is a library that applies multiple numerical transformations to the features in order to find meaningful relationships between features and target, improving the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['resign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "autofeat_full = AutoFeatClassifier(feateng_cols=og_train_df.columns.tolist(), n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 07:32:55,360 INFO: [AutoFeat] The 2 step feature engineering process could generate up to 74305 features.\n",
      "2024-07-28 07:32:55,362 INFO: [AutoFeat] With 2152 data points this new feature matrix would use about 0.64 gb of space.\n",
      "2024-07-28 07:32:55,365 INFO: [feateng] Step 1: transformation of original features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]               0/             55 features transformed\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 07:32:57,622 INFO: [feateng] Generated 222 transformed features from 55 original features - done.\n",
      "2024-07-28 07:32:57,626 INFO: [feateng] Step 2: first combination of features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]           23700/          38226 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_Science\\high_performance_employee_resign_prediction\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:247: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]           38100/          38226 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 07:33:15,824 INFO: [feateng] Generated 38062 feature combinations from 38226 original feature tuples - done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]           38200/          38226 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 07:33:16,245 INFO: [feateng] Generated altogether 38293 new features in 2 steps\n",
      "2024-07-28 07:33:16,246 INFO: [feateng] Removing correlated features, as well as additions at the highest level\n",
      "2024-07-28 07:33:17,971 INFO: [feateng] Generated a total of 33538 additional features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data...done.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 117.4min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 117.5min remaining: 176.3min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 117.6min remaining: 78.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 118.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 118.6min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:31:53,619 INFO: [featsel] 46 features after 5 feature selection runs\n",
      "2024-07-28 09:31:54,101 INFO: [featsel] 46 features after correlation filtering\n",
      "2024-07-28 09:31:57,537 INFO: [featsel] 29 features after noise filtering\n",
      "2024-07-28 09:31:57,547 INFO: [AutoFeat] Computing 27 new features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]    24/   27 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:32:00,517 INFO: [AutoFeat]    27/   27 new features ...done.\n",
      "2024-07-28 09:32:00,522 INFO: [AutoFeat] Final dataframe with 82 feature columns (27 new).\n",
      "2024-07-28 09:32:00,523 INFO: [AutoFeat] Training final classification model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]    26/   27 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:32:01,327 INFO: [AutoFeat] Trained model: largest coefficients:\n",
      "2024-07-28 09:32:01,328 INFO: [-1.33402973]\n",
      "2024-07-28 09:32:01,329 INFO: 5.346941 * gender_boss*gender_employee\n",
      "2024-07-28 09:32:01,329 INFO: 1.511400 * sqrt(marital_estatus_employee)*seniority_employee\n",
      "2024-07-28 09:32:01,329 INFO: 1.487994 * seniority_employee*exp(avg_lhd_bpb)\n",
      "2024-07-28 09:32:01,330 INFO: 0.876908 * gender_boss\n",
      "2024-07-28 09:32:01,330 INFO: 0.775278 * performance_employee*performance_score_employee\n",
      "2024-07-28 09:32:01,331 INFO: 0.757423 * gender_employee*performance_employee\n",
      "2024-07-28 09:32:01,332 INFO: 0.673955 * gender_employee\n",
      "2024-07-28 09:32:01,333 INFO: 0.474227 * gender_boss*Abs(join_age_boss)\n",
      "2024-07-28 09:32:01,333 INFO: 0.446958 * gender_employee*sqrt(recruitment_channel_employee)\n",
      "2024-07-28 09:32:01,333 INFO: 0.376649 * sqrt(marital_estatus_employee)*Abs(performance_score_boss)\n",
      "2024-07-28 09:32:01,334 INFO: 0.373801 * gender_employee*Abs(salary_employee)\n",
      "2024-07-28 09:32:01,334 INFO: 0.334256 * gender_boss*sqrt(recruitment_channel_employee)\n",
      "2024-07-28 09:32:01,335 INFO: 0.302912 * low_health_days_employee*Abs(avg_lhd_bpb)\n",
      "2024-07-28 09:32:01,335 INFO: 0.282755 * work_modality_boss*work_modality_employee\n",
      "2024-07-28 09:32:01,336 INFO: 0.279698 * gender_employee*sqrt(marital_estatus_employee)\n",
      "2024-07-28 09:32:01,336 INFO: 0.210788 * sqrt(marital_estatus_employee)*Abs(psi_score_employee)\n",
      "2024-07-28 09:32:01,337 INFO: 0.178170 * performance_score_employee*salary_employee**2\n",
      "2024-07-28 09:32:01,337 INFO: 0.121813 * gender_employee*exp(low_health_days_employee)\n",
      "2024-07-28 09:32:01,338 INFO: 0.106916 * exp(avg_ps_epb)*Abs(psi_score_boss)\n",
      "2024-07-28 09:32:01,338 INFO: 0.105525 * low_health_days_employee*exp(join_days_diff)\n",
      "2024-07-28 09:32:01,338 INFO: 0.080547 * performance_score_employee*exp(avg_sal_epb)\n",
      "2024-07-28 09:32:01,340 INFO: 0.080296 * avg_sal_epb*exp(average_permanence_employee)\n",
      "2024-07-28 09:32:01,340 INFO: 0.059008 * Abs(avg_avgp_bpb)/avg_od_epb\n",
      "2024-07-28 09:32:01,341 INFO: 0.023851 * bob_bosses_in_charge**3/avg_lhd_bpb\n",
      "2024-07-28 09:32:01,341 INFO: 0.020243 * work_modality_employee*exp(recruitment_channel_employee)\n",
      "2024-07-28 09:32:01,341 INFO: 0.008153 * gender_boss*id_last_boss_employee\n",
      "2024-07-28 09:32:01,342 INFO: 0.007734 * low_health_days_employee**3/average_permanence_diff\n",
      "2024-07-28 09:32:01,342 INFO: 0.006241 * salary_employee**2/boss_employees_in_charge\n",
      "2024-07-28 09:32:01,343 INFO: 0.002158 * marital_estatus_employee**3*exp(marital_estatus_employee)\n",
      "2024-07-28 09:32:01,344 INFO: [AutoFeat] Final score: 0.7904\n"
     ]
    }
   ],
   "source": [
    "# Applying automatic feature engineering\n",
    "\n",
    "X_train_full_transf = autofeat_full.fit_transform(og_train_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 12:47:25,851 INFO: [AutoFeat] Computing 27 new features.\n",
      "2024-07-28 12:47:25,871 INFO: [AutoFeat]    27/   27 new features ...done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]    26/   27 new features\r"
     ]
    }
   ],
   "source": [
    "X_test_full_transf = autofeat_full.transform(og_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering on reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autofeat_red = AutoFeatClassifier(feateng_cols=og_reduced_train_df.columns.tolist(), n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:32:01,408 INFO: [AutoFeat] The 2 step feature engineering process could generate up to 8911 features.\n",
      "2024-07-28 09:32:01,408 INFO: [AutoFeat] With 2152 data points this new feature matrix would use about 0.08 gb of space.\n",
      "2024-07-28 09:32:01,409 INFO: [feateng] Step 1: transformation of original features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]               0/             19 features transformed\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:32:03,004 INFO: [feateng] Generated 69 transformed features from 19 original features - done.\n",
      "2024-07-28 09:32:03,007 INFO: [feateng] Step 2: first combination of features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            3000/           3828 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_Science\\high_performance_employee_resign_prediction\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:247: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            3500/           3828 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:32:04,943 INFO: [feateng] Generated 3783 feature combinations from 3828 original feature tuples - done.\n",
      "2024-07-28 09:32:04,979 INFO: [feateng] Generated altogether 3858 new features in 2 steps\n",
      "2024-07-28 09:32:04,980 INFO: [feateng] Removing correlated features, as well as additions at the highest level\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]            3800/           3828 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:32:05,130 INFO: [feateng] Generated a total of 2717 additional features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[featsel] Scaling data...done.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 10.3min remaining: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 10.4min remaining:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 10.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:42:45,614 INFO: [featsel] 36 features after 5 feature selection runs\n",
      "2024-07-28 09:42:45,623 INFO: [featsel] 36 features after correlation filtering\n",
      "2024-07-28 09:42:49,269 INFO: [featsel] 27 features after noise filtering\n",
      "2024-07-28 09:42:49,271 INFO: [AutoFeat] Computing 25 new features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]    22/   25 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:42:52,233 INFO: [AutoFeat]    25/   25 new features ...done.\n",
      "2024-07-28 09:42:52,236 INFO: [AutoFeat] Final dataframe with 44 feature columns (25 new).\n",
      "2024-07-28 09:42:52,237 INFO: [AutoFeat] Training final classification model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]    24/   25 new features\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 09:42:52,315 INFO: [AutoFeat] Trained model: largest coefficients:\n",
      "2024-07-28 09:42:52,316 INFO: [-1.97994311e-06]\n",
      "2024-07-28 09:42:52,317 INFO: 0.001621 * exp(performance_score_employee)*exp(recruitment_channel_employee)\n",
      "2024-07-28 09:42:52,318 INFO: 0.000856 * marital_estatus_employee**3*exp(marital_estatus_employee)\n",
      "2024-07-28 09:42:52,318 INFO: 0.000648 * avg_ps_epb**3*marital_estatus_employee**3\n",
      "2024-07-28 09:42:52,319 INFO: 0.000293 * work_modality_employee*exp(recruitment_channel_employee)\n",
      "2024-07-28 09:42:52,319 INFO: 0.000130 * gender_employee/performance_score_boss\n",
      "2024-07-28 09:42:52,319 INFO: 0.000077 * performance_score_employee*exp(performance_score_boss)\n",
      "2024-07-28 09:42:52,320 INFO: 0.000075 * sqrt(id_last_boss_employee)*sqrt(recruitment_channel_employee)\n",
      "2024-07-28 09:42:52,320 INFO: 0.000070 * low_health_days_diff/performance_score_employee\n",
      "2024-07-28 09:42:52,321 INFO: 0.000059 * Abs(avg_ja_epb)/low_health_days_employee\n",
      "2024-07-28 09:42:52,322 INFO: 0.000056 * work_modality_employee*exp(performance_score_employee)\n",
      "2024-07-28 09:42:52,322 INFO: 0.000049 * work_modality_employee*exp(avg_ps_epb)\n",
      "2024-07-28 09:42:52,323 INFO: 0.000049 * low_health_days_employee*exp(join_days_diff)\n",
      "2024-07-28 09:42:52,323 INFO: 0.000046 * Abs(performance_score_employee)/performance_score_employee\n",
      "2024-07-28 09:42:52,324 INFO: 0.000039 * performance_employee*salary_diff**2\n",
      "2024-07-28 09:42:52,324 INFO: 0.000036 * join_days_diff**3*performance_employee\n",
      "2024-07-28 09:42:52,324 INFO: 0.000029 * gender_employee*performance_score_employee\n",
      "2024-07-28 09:42:52,325 INFO: 0.000029 * performance_employee*performance_score_employee\n",
      "2024-07-28 09:42:52,325 INFO: 0.000025 * low_health_days_employee\n",
      "2024-07-28 09:42:52,326 INFO: 0.000011 * Abs(performance_score_boss)*Abs(salary_diff)\n",
      "2024-07-28 09:42:52,326 INFO: 0.000010 * sqrt(marital_estatus_employee)*Abs(performance_score_boss)\n",
      "2024-07-28 09:42:52,328 INFO: [AutoFeat] Final score: 0.5627\n"
     ]
    }
   ],
   "source": [
    "# Applying automatic feature engineering\n",
    "\n",
    "X_train_red_transf = autofeat_red.fit_transform(og_reduced_train_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 12:49:05,768 INFO: [AutoFeat] Computing 25 new features.\n",
      "2024-07-28 12:49:05,790 INFO: [AutoFeat]    25/   25 new features ...done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat]    24/   25 new features\r"
     ]
    }
   ],
   "source": [
    "X_test_red_transf = autofeat_red.transform(og_reduced_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving full data\n",
    "\n",
    "full_train_df = pd.concat([train_id, X_train_full_transf, node_feat_train], axis=1)\n",
    "full_test_df = pd.concat([test_id, X_test_full_transf, node_feat_test], axis=1)\n",
    "\n",
    "full_train_df.to_csv(paths.data_processed_dir('train_processed.csv'), index=False, sep=',')\n",
    "full_test_df.to_csv(paths.data_processed_dir('test_processed.csv'), index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving reduced data\n",
    "\n",
    "red_train_df = pd.concat([train_id, X_train_red_transf, node_feat_train], axis=1)\n",
    "red_test_df = pd.concat([test_id, X_test_red_transf, node_feat_test], axis=1)\n",
    "\n",
    "red_train_df.to_csv(paths.data_processed_dir('train_reduced_processed.csv'), index=False, sep=',')\n",
    "red_test_df.to_csv(paths.data_processed_dir('test_reduced_processed.csv'), index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving reduced data but with autofeat generated columns with full data\n",
    "\n",
    "full_red_train_df = pd.concat([train_id, og_reduced_train_df, X_train_full_transf.iloc[:, -27:], node_feat_train], axis=1)\n",
    "full_red_test_df = pd.concat([test_id, og_reduced_test_df, X_test_full_transf.iloc[:, -27:], node_feat_test], axis=1)\n",
    "\n",
    "full_red_train_df.to_csv(paths.data_processed_dir('train_full_red_processed.csv'), index=False, sep=',')\n",
    "full_red_test_df.to_csv(paths.data_processed_dir('test_full_red_processed.csv'), index=False, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
